{
  "base_url": "https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code",
  "max_depth": 1,
  "max_links": 1,
  "total_crawled": 1,
  "pages": {
    "https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code": {
      "url": "https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code",
      "success": true,
      "content_type": "text/html",
      "is_binary": false,
      "title": "AI Is Forcing Us To Write Good Code - by Steve Krenzel",
      "meta_description": "When Best Practices Are Best",
      "text_content": "Bits of Logic\nSubscribe\nSign in\nAI Is Forcing Us To Write Good Code\nWhen Best Practices Are Best\nSTEVE KRENZEL\nDEC 30, 2025\n17\n2\nShare\n\nFor decades, we’ve all known what “good code” looks like. Thorough tests. Clear documentation. Small, well-scoped modules. Static typing. Dev environments you can spin up without a minor religious ritual.\n\nThese things were always optional, and time pressure usually meant optional got cut.\n\nAgents need these optional things though. They aren’t great at making a mess and cleaning it up later. Agents will happily be the Roomba that rolls over dog poop and drags it all over your house.\n\nThe only guardrails are the ones you set and enforce. If the agentic context is lacking and the guardrails aren’t sufficient, you’ll find yourself in a world of pain1. But if the guardrails are solid, the LLM can bounce around tirelessly until the only path out is the correct one.\n\nOur six-person team has made a lot of specific and, sometimes, controversial investments to accommodate our agentic coders. Let’s talk about some of the less obvious ones.\n\n100% Percent Code Coverage\n\nThe most controversial guideline we have is our most valuable: We require 100% code coverage2.\n\nEveryone is skeptical when they hear this until they live with it for a day. It feels like a secret weapon at times.\n\nCoverage, as we use it, isn’t strictly about bug prevention; it’s about guaranteeing the agent has double-checked the behavior of every line of code it wrote.\n\nThe usual misinterpretation is that people think we believe 100% coverage means “no bugs”. Or that we’re chasing a metric, and metrics get gamed. Neither of those are the case here.\n\nWhy 100%? At 95% coverage, you’re still making decisions about what’s “important enough” to test. At 99.99%, you don’t know if that uncovered line in ./src/foo.ts was there before you started work on the new feature. At 100%, there’s a phase change and all of that ambiguity goes away3. If a line isn’t covered, it’s because of something you actively just did.\n\nThe coverage report becomes a simple todo list of tests you still need to write. It’s also one less degree of freedom we have to give to the agent to reason about.\n\nAt 100% coverage, the leverage you get from the tests experiences a step-function increase.\n\nWhen a model adds or changes code, we force it to demonstrate how that line behaves. It can’t stop at “this seems right.” It has to back it up with an executable example.\n\nOther nice benefits: Unreachable code gets deleted. Edge cases are made explicit. And code reviews become easier because you see concrete examples of how every aspect of the system is expected to behave or change.\n\nNamespaces Are One Honking Great Idea. Let’s do more of those.4\n\nThe main mechanism agentic tools use to navigate your codebase is the filesystem. They list directories, read filenames, search for strings, and pull files into context.\n\nYou should treat your directory structure and file naming with the same thoughtfulness you’d treat any other interface.\n\nA file called ./billing/invoices/compute.ts communicates much more than ./utils/helpers.ts, even if the code inside is identical. Help the LLM out and give your files thoughtful organization.\n\nAdditionally, prefer many small well-scoped files.\n\nIt improves how context gets loaded. Agents often summarize or truncate large files when they pull them into their working set. Small files reduce that risk. If a file is short enough to be loaded in full, the model can keep the entire thing active in context.\n\nIn practice, it will speed up the agent’s flow and eliminate a whole class of degraded performance.\n\nFast, Ephemeral, Concurrent Dev Environments\n\nIn the old world, you lived in one dev environment. This is where you’d craft your perfect solution, tweak things, run commands, restart servers, and gradually converge on a solution.\n\nWith agents, you do something closer to beekeeping, orchestrating across processes without knowing the specifics of what exactly is happening within each of them. So you need to cultivate a good and healthy hive.\n\nFast\n\nYou need your automated guardrails to run quickly, because you need to run them often.\n\nThe goal is to keep the agent on a short leash: make a small change, check it, fix it, repeat.\n\nYou can run them a few ways: agent hooks, git hooks, or just prompting (i.e. in your AGENTS.md), but no matter how you run them, your quality checks need to be cheap enough that running them constantly is not slowing things down.\n\nIn our setup, every npm test creates a brand new database, runs migrations, and executes the full suite.\n\nThis only works for us because we’ve made each of those stages exceptionally fast. We run tests with high concurrency, strong isolation, and a caching layer for third-party calls5. We have 10,000+ assertions that finish in about a minute. Without caching, it takes 20-30 minutes, which would add hours if you expected an agent to run tests several times per task.\n\nEphemeral\n\nOnce you get comfortable with agents, you naturally start running many of them. You’ll spin up and tear down many dev environments multiple times a day. That has to all be fully automated or you’ll avoid doing it.\n\nWe have a simple workflow here:\n\nnew-feature <name>\n\nThat command creates a new git worktree, copies in local config that doesn’t live in git (like .env files), installs dependencies, and then starts your agent with a prompt to interview you to write a PRD together. If the feature name is descriptive enough, it may even just ask to get right to work, assuming it can figure out the rest of the context on its own.\n\nThe important part isn’t our specific scripts. It’s the latency. If it takes minutes and involves a bunch of tinkering and manual configuration, you won’t do it. If it is one command and takes 1-2 seconds, you’ll do it constantly.\n\nIn our case, one command gives you a fresh, working environment almost immediately, with an agent ready to start.\n\nConcurrent\n\nThe final piece is being able to run each environment at the same time. Having a bunch of worktrees doesn’t help if you can only have one of them active at a time.\n\nThat means anything that could conflict (e.g. ports, database names, caches, background jobs) needs to be configurable (ideally via environment variables) or otherwise allocated in some conflict-free way.\n\nIf you use Docker you get some of this for free, but the general requirement is the same: you need a solid isolation story so you can run several fully functioning dev environments on one machine without cross-talk.\n\nEnd-To-End Types\n\nMore broadly, automate the enforcement of as many best practices as you can. Remove degrees of freedom from the LLM. If you’re not already using automatic linters and formatters6, start there. Make those as strict as possible and configured to automatically apply fixes whenever the LLM finishes a task or is about to commit7.\n\nBut you should also be using a typed language8.\n\nEntire categories of illegal states and transitions can be eliminated. And types shrink the search space of possible actions the model can take, while doubling as source-of-truth documentation describing exactly what kind of data flows through each layer.\n\nTypeScript\n\nWe lean on TypeScript pretty heavily. If something can be reasonably represented cleanly in the type system, we do it.\n\nAnd we push semantic meaning into the type names. The goal is to make “what is this?” and “where does it go?” answerable at a glance.\n\nWhen you’re working with agents, good semantic names are an amplifier. If the model sees a type like UserId, WorkspaceSlug, or SignedWebhookPayload, it can immediately understand what kind of thing it is dealing with. It can also search for that thing easily.\n\nGeneric names like T are fine when you’re writing a small self-contained generic algorithm, but much less helpful when you’re communicating intent inside a real business system.\n\nOpenAPI\n\nOn the API side, we use OpenAPI and generate well-typed clients, so the frontend and backend agree on shapes.\n\nPostgres\n\nOn the data side, we use Postgres’ type system as best as we can, and add checks and triggers for invariants that don’t fit into simple column types. Postgres doesn’t have a particularly rich type system, but it has enough there to enforce a surprising amount of correctness. If an agent tries to write invalid data, our database will usually complain clearly and loudly. And we use Kysely to generate well-typed TypeScript clients for us.\n\nAll of our other 3rd-party clients either give us good types, or we wrap them to give us good types.\n\nAgents are tireless and often brilliant coders, but they’re only as effective as the environment you place them in. Once you realize this, “good code” stops feeling superfluous and starts feeling essential.\n\nYes, the upfront work feels like a tax, but it’s the same tax we’ve all been dodging for years. So pay it intentionally. Put it on your agentic roadmap, get it funded by eng leadership, and finally ship the codebase you always hoped for.\n\nSubscribe\n1\n\nOften, when teams struggle with agentic coding, it’s AI reflecting and amplifying their codebase’s worst tendencies.\n\n2\n\n100% coverage is actually the minimum bar we set. We encourage writing tests for as many scenarios as is possible, even if it means the same lines getting exercised multiple times. It gets us closer to 100% path coverage as well, though we don’t enforce (or measure) that.\n\n3\n\nIt’s also remarkably easy to maintain 100% once you hit it. The coverage report enumerates exactly what lines need testing, which the LLM happily handles.\n\n4\n\nWe personally like Biome,\n\n5\n\nAmong other mechanisms, we use githooks for this.\n\n6\n\nDon’t use Python. Even with type annotations. Just use TypeScript. It makes me a little sad to say, having written Python for 20+ years, but TypeScript’s is just a much better type system.\n\n7\n\nhttps://peps.python.org/pep-0020/#the-zen-of-python\n\n8\n\nWhen we run tests in CI/CD, after the PR is approved, we run them without caching just to ensure there wasn’t a subtle assumption violated by the cache. It also double-checks that we’re still talking to all of our 3rd-party integrations correctly.\n\nSubscribe to Bits of Logic\nAI, automation, and decision intelligence.\nSubscribe\nBy subscribing, I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.\n17 Likes\n∙\n2 Restacks\n17\n2\nShare\nPrevious\nNext\nDiscussion about this post\nComments\nRestacks\nTop\nLatest\nDiscussions\nCodex is a Slytherin, Claude is a Hufflepuff\nA Highly Unscientific Assessment of AI Coding Agents\nDEC 23 • BEN\n10\n2\nGetting gpt-4o-mini to perform like gpt-4o\nFew-Shot Knowledge Distillation\nDEC 31, 2024 • STEVE KRENZEL\n6\n1\nHo-Ho-How to Make ChatGPT Sound Like Santa Claus!\nCreating a custom ChatGPT Santa Claus for the little loved ones in your life.\nDEC 22, 2024 • STEVE KRENZEL\nSee all\nReady for more?\nSubscribe\n© 2025 Logic, Inc. · Privacy ∙ Terms ∙ Collection notice\nStart your Substack\nGet the app\nSubstack is the home for great culture",
      "html_length": 274569,
      "links": [
        "https://substack.com/@stevekrenzel",
        "https://substackcdn.com/image/fetch/$s_!M5s0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0d94e7a-5c6a-4801-a96c-4e2104f96419_2752x1536.jpeg",
        "https://substack.com/profile/4628073-max-olson",
        "https://bits.logic.inc/p/ai-is-forcing-us-to-write-good-code",
        "https://substack.com/ccpa",
        "https://substackcdn.com/image/fetch/$s_!ME7a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6927228-e121-41b0-8cbe-9b96d8b0a13d_2752x1536.jpeg",
        "https://substackcdn.com/image/fetch/$s_!YIal!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19ade39f-158a-485b-b6c2-a995a928b8aa_2752x1536.jpeg",
        "https://bits.logic.inc/p/getting-gpt-4o-mini-to-perform-like",
        "https://bits.logic.inc/p/engineering-is-becoming-beekeeping",
        "https://substack.com/privacy",
        "https://bits.logic.inc/",
        "https://substack.com/profile/258707170-gregory-tod",
        "https://substack.com/tos",
        "https://substack.com/@ben1783490",
        "https://biomejs.dev/",
        "https://substackcdn.com/image/fetch/$s_!7kIE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ce50397-2e75-4be5-b8c4-071e7d6cd36a_1200x896.png",
        "https://substackcdn.com/image/fetch/$s_!WdHC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc53a3f7e-3b45-4192-9e4e-e08c88d2a6fc_2752x1536.jpeg",
        "https://github.com/with-logic/fast-forward",
        "https://peps.python.org/pep-0020",
        "https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer",
        "https://logic.inc/",
        "https://kysely.dev/",
        "https://substack.com/profile/6963996-henning-spjelkavik",
        "https://bits.logic.inc/p/codex-is-a-slytherin-claude-is-a",
        "https://substack.com/profile/291497-steven-hudson",
        "https://substack.com/",
        "https://substackcdn.com/image/fetch/$s_!Ml4F!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6926e-35fe-448d-9bbe-9b87f61d0c2f_2752x1536.jpeg",
        "https://substack.com/profile/116161372-mbfk",
        "https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button",
        "https://substack.com/note/p-182812243/restacks?utm_source=substack&utm_content=facepile-restacks",
        "https://bits.logic.inc/p/ho-ho-how-to-make-chatgpt-sound-like"
      ]
    }
  }
}